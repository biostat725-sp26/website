---
title: "AE 10: Bayesian Clustering"
subtitle: "Clustering patients based on their ED length of stay"
date: "April 8, 2025"
---

::: callout-important
## Due date

Application exercises (AEs) are submitted by pushing your work to the relevant GitHub repo. AEs from Tuesday lectures should be submitted by Friday by 11:59pm ET, and AEs from Thursday lectures should be submitted by Sunday at 11:59pm ET. Because AEs are intended for in-class activities, there are no extensions given on AEs.

-   Final `.qmd` and `.pdf` files pushed to your GitHub repo
-   **Note:** For homeworks and exams, you will also be required to submit your final `.pdf` file submitted on Gradescope
:::

# Getting Started

## Clone the repo & start new RStudio project

-   Go to the course organization at [github.com/biostat725-sp25](https://github.com/biostat725-sp25) organization on GitHub.
-   Click on the repo with the prefix **ae-10-**. It contains the starter documents you need to complete the AE.
-   Click on the green **CODE** button, select **Use SSH** (this might already be selected by default, and if it is, you'll see the text **Clone with SSH**). Click on the clipboard icon to copy the repo URL.
    -   See the [HW 00 instructions](https://biostat725-sp25.netlify.app/hw/hw-00#connect-rstudio-and-github) if you have not set up the SSH key or configured git.
-   In RStudio, go to *File* $\rightarrow$ *New Project* $\rightarrow$ *Version Control* $\rightarrow$ *Git*.
-   Copy and paste the URL of your assignment repo into the dialog box *Repository URL*. Again, please make sure to have *SSH* highlighted under *Clone* when you copy the address.
-   Click *Create Project*, and the files from your GitHub repo will be displayed in the *Files* pane in RStudio.
-   Click `ae-10.qmd` to open the template Quarto file. This is where you will write up your code and narrative for the AE.

# R packages

We will begin by loading R packages that we will use in this AE.

```{r}
#| label: load-packages
#| message: false

library(tidyverse)     # data wrangling and visualization
library(knitr)         # format output
library(rstan)         # Stan
library(bayesplot)     # figures for post Stan inference
library(loo)           # model comparison
library(patchwork)     # combining figures
library(extraDistr)    # student-t density function  

options(mc.cores=4)
```

# Data

This AE will revisit data from the MIMIC-IV-ED Demo. As a reminder, MIMIC-IV-ED is a publicly accessible database of over 400,000 emergency department (ED) admissions to the Beth Israel Deaconess Medical Center between 2011 and 2019. The emergency department (ED) is a high demand environment requiring rapid triaging of patients for further care.

For the AE, we will use data on patient lengths of stay, `los`. The data are available in your repo (`ed_los.rds`).

```{r, message = FALSE, warning = FALSE, eval = FALSE}
ed_los <- readRDS("ed_los.rds")
```


```{r, message = FALSE, warning = FALSE, echo = FALSE}
ed_los <- readRDS("/Users/sib2/Box Sync/Faculty/Education/biostat725-sp25/repos/ae-10/ed_los.rds")
```

```{r, message = FALSE, warning = FALSE, echo = T}
ggplot(ed_los, aes(x = los)) + 
  geom_histogram() + 
  labs(x = "ED Length of Stay (hours)",
       y = "Count") 
```

Note the multimodality. As described in the lecture, our goal will be to identify subgroups within these data.

# Model Goals

Compare fit from two models

\begin{align*}
p\left(Y_i\mid \pi, \mu, \sigma\right) &= \sum_{h=1}^2 \pi_h N\left(Y_i; \mu_h, \sigma^2_h\right) \\
\mu_h &\sim N\left(0,10^2\right) \\
\sigma_h &\sim \text{Exp}\left(1\right) \\
\pi_1\sim\text{Unif}(0,1), &\quad\quad \pi_2=1-\pi_h
\end{align*}

and

\begin{align*}
p\left(Y_i\mid \pi, \mu, \sigma\right) &= \sum_{h=1}^2 \pi_h t_{\nu_h}\left(Y_i; \mu_h, \sigma^2_h\right) \\
\mu_h &\sim N\left(0,10^2\right) \\
\sigma_h &\sim N_+\left(2, 0.5^2\right) \\
\nu_h &\sim \text{Ga}\left(5, 0.5\right) \\
\pi_1\sim\text{Unif}(0,1), &\quad\quad \pi_2=1-\pi_h
\end{align*}

## Fitting the Model

Because clustering is generally an unsupervised task, no covariates are used to fit the model. We will use a centered outcome $Y_i - \bar{Y}$ to simplify prior specification. In addition to the outcome $Y$, we must specify the number of components (clusters) $k$ used to fit the mixture. The Stan data object is given by

```{r}
stan_data <- list(Y = (ed_los$los - mean(ed_los$los)),
                  n = length(ed_los$los),
                  k = 2)
```

We will now fit the model and print the posterior summaries and MCMC convergence diagnostics.

**Gaussian components:**

```{r, eval = FALSE, echo=TRUE}
mixture_gauss <- stan_model("mixture1.stan")
fit_mixture_k2g <- sampling(mixture_gauss, data=stan_data, iter=5000, chains=4, control=list("adapt_delta"=0.99))

print(fit_mixture_k2g, pars = c("pi", "mu", "sigma"))
```

```{r, eval = TRUE, echo=FALSE}
fit_mixture_k2g <- readRDS("/Users/sib2/Box Sync/Faculty/Education/biostat725-sp25/repos/725bayesclust4/fits/fit1.rds")
print(fit_mixture_k2g, pars = c("pi", "mu", "sigma"))
```

Traceplots and pair plots of posterior samples reveal bimodality:

```{r}
rstan::traceplot(fit_mixture_k2g, pars = c("pi", "mu", "sigma"))
```

```{r warning=FALSE}
pairs(fit_mixture_k2g, pars = c("mu", "sigma"))
```

```{r, eval=TRUE, echo=FALSE}
samples <- rstan::extract(fit_mixture_k2g)

gmix <- function(x, pi, mu, sigma){
  return(pi * dnorm(x, mu, sigma))
}

base <- ggplot() + 
  geom_histogram(aes(x=stan_data$Y, y=after_stat(count)/sum(after_stat(count))), 
                 binwidth = 1.25) + 
            ylab("Density") + xlab("Y") + ggtitle("Posterior Gaussian Mixture Samples (solid, gold/turquoise)")

for (it in sample(1:4000, 100)){
  base <- base + geom_function(xlim=c(min(stan_data$Y)-5, max(stan_data$Y)+5), fun=gmix, 
                               args=list(pi=samples$pi[it,1],
                                         mu=samples$mu[it,1], sigma=samples$sigma[it,1]), 
                               n=1000, color="gold2", alpha=0.35, linewidth=0.25) + 
                 geom_function(xlim=c(min(stan_data$Y)-5, max(stan_data$Y)+5), fun=gmix, 
                               args=list(pi=samples$pi[it,2],
                                         mu=samples$mu[it,2], sigma=samples$sigma[it,2]), 
                               n=1000, color="turquoise", alpha=0.35, linewidth=0.25, linetype=1) 
}

base
# + 
#    geom_function(xlim=c(min(stan_data$Y)-5, max(stan_data$Y)+5), fun=gmix, 
#                       args=list(pi=samples$pi[,1]|>mean(),
#                                 mu=samples$mu[,1]|>mean(), sigma=samples$sigma[,1]|>mean()), 
#                       n=1000, color="black", linetype="dashed", linewidth=0.75) + 
#   geom_function(xlim=c(min(stan_data$Y)-5, max(stan_data$Y)+5), fun=gmix, 
#                 args=list(pi=samples$pi[,2]|>mean(),
#                           mu=samples$mu[,2]|>mean(), sigma=samples$sigma[,2]|>mean()), 
#                 n=1000, color="black", linetype="dashed", linewidth=0.75) 

```

*Posterior means are not meaningful in this case*

**Student t components:**

```{r, eval = FALSE, echo=TRUE}
mixture_t <- stan_model("mixture2.stan")
fit_mixture_k2t <- sampling(mixture_t, data=stan_data, iter=5000, chains=4)
print(fit_mixture_k2t, pars = c("pi", "mu", "sigma", "nu"))
```

```{r, eval = TRUE, echo=FALSE}
fit_mixture_k2t <- readRDS("/Users/sib2/Box Sync/Faculty/Education/biostat725-sp25/repos/725bayesclust4/fits/fit2.rds")
print(fit_mixture_k2t, pars = c("pi", "mu", "sigma", "nu"))
```

```{r}
rstan::traceplot(fit_mixture_k2t, pars = c("pi", "mu", "sigma", "nu"))
```

```{r, eval=T, echo=F}
samples <- rstan::extract(fit_mixture_k2t)

tmix <- function(x, pi, df, mu, sigma){
  return(pi * dlst(x, df, mu, sigma))
}

base <- ggplot() + 
  geom_histogram(aes(x=stan_data$Y, y=after_stat(count)/sum(after_stat(count))), 
                 binwidth = 1.25) + 
            ylab("Density") + xlab("Y") + ggtitle("Posterior t Mixture Samples (solid, gold/turquoise) + Component Means (dashed, black)")

for (it in sample(1:4000, 100)){
  base <- base + geom_function(xlim=c(min(stan_data$Y)-5, max(stan_data$Y)+5), fun=tmix, 
                               args=list(pi=samples$pi[it,1], df=samples$nu[it,1], 
                                         mu=samples$mu[it,1], sigma=samples$sigma[it,1]), 
                               n=1000, color="gold2", alpha=0.35, linewidth=0.25) + 
                 geom_function(xlim=c(min(stan_data$Y)-5, max(stan_data$Y)+5), fun=tmix, 
                               args=list(pi=samples$pi[it,2], df=samples$nu[it,2], 
                                         mu=samples$mu[it,2], sigma=samples$sigma[it,2]), 
                               n=1000, color="turquoise", alpha=0.35, linewidth=0.25, linetype=1) 
}

base + 
   geom_function(xlim=c(min(stan_data$Y)-5, max(stan_data$Y)+5), fun=tmix, 
                      args=list(pi=samples$pi[,1]|>mean(), df=samples$nu[,1]|>mean(), 
                                mu=samples$mu[,1]|>mean(), sigma=samples$sigma[,1]|>mean()), 
                      n=1000, color="black", linetype="dashed", linewidth=0.75) + 
  geom_function(xlim=c(min(stan_data$Y)-5, max(stan_data$Y)+5), fun=tmix, 
                args=list(pi=samples$pi[,2]|>mean(), df=samples$nu[,2]|>mean(), 
                          mu=samples$mu[,2]|>mean(), sigma=samples$sigma[,2]|>mean()), 
                n=1000, color="black", linetype="dashed", linewidth=0.75) 

```

## Visualizing $\text{Pr}(z_i=z_j|-)$

For t mixture:

```{r warning=FALSE}
#| echo: FALSE
ccmat <- matrix(1, stan_data$n, stan_data$n)
for (i in 1:(stan_data$n-1)){
  for (j in (i+1):stan_data$n){
    ccmat[i,j] <- mean(samples$z[,i] ==samples$z[,j])
    ccmat[j,i] <- ccmat[i,j]
  }
}
colnames(ccmat) <- paste0("Y", 1:stan_data$n)
rownames(ccmat) <- paste0("Y", 1:stan_data$n)

ccmat <- ccmat[order(stan_data$Y, decreasing = F),order(stan_data$Y, decreasing = F)]

stan_data2 <- reshape::melt(ccmat)

ggplot(stan_data2, aes(X1, X2)) +
  geom_tile(aes(fill = value)) +
  # geom_text(aes(label = round(value, 1))) +
  scale_fill_gradient(low = "blue", high = "red", name = bquote("Pr(" ~ z[i]~"="~z[j] ~ "|"-")")) + 
  theme(axis.text = element_blank()) + 
  xlab("Y rank") + ylab("Y rank") + coord_equal() 
```

# Exercises

## Exercise 1

Revisit the Gaussian mixture model fit above. Diagnostic criteria indicate that the posterior samples collected may not faithfully represent the true posterior. Traceplots and pair plots indicate that different chains explored different regions of the posterior. Discuss the following: Why might the true posterior be multimodal? Is this a problem with the model or with the way we compute the posterior?

**Answer:**

Points students may consider: - Without the `ordered` constraint, the model is trivially multimodal with modes corresponding to switched labels. - The `ordered` constraint on $\mu$ is intended to resolve non-identifiability (label switching). If, under the data generating process $\mu_1\approx\mu_2$ however, then the constraint fails to prevent switching between the variances. I.e., ordering $\mu$ does not resolve label switching in a variance mixture of Gaussians model. - Notice that the chains do not mix over modesâ€”each chain is apparently stuck in one of the two modes. Hence, no single chain is actually exploring the disjoint region of high posterior probability. This is a limitation of the posterior computation method. - If chains did mix over modes, however, summarizing the posterior would be nontrivial.

## Exercise 2

Extend the Gaussian mixture model Stan code to simulate data `Y_pred` under the posterior predictive. Compare the density of predicted data to the empirical density of observed data. Do you observe anything surprising?

**Answer:**

This is a bit tricky because the posterior probability that large $Y$ comes from the small component is numerically zero.

Hopefully students not that many of the marginal posteriors for `Y_pred` are well-behaved in terms of ESS and Rhat. Maybe we can estimate the density well without nailing the parameters. The density overlay is reasonable with obvious problems around the interval $(5,15)$.

```{r}
#| label: ex2

# add code here

```

```{stan eval=FALSE, echo=T, output.var="ex2"}
generated quantities {
  array[n] real Y_pred;
  matrix[n,k] lPrZik;
  int<lower=1, upper=k> z[n];
  
  for (i in 1:n){
    for (h in 1:k){
      lPrZik[i,h] = log(pi[h]) + normal_lpdf(Y[i] | mu[h], sigma[h]);
    }
    lPrZik[i] -= log(sum(exp(lPrZik[i])));
    
    // Numerical zeros due to light tails complicate predictive inference
    if (is_inf(exp(lPrZik[i,1]))){
      z[i] = 1;
      Y_pred[i] = normal_rng(mu[z[i]], sigma[z[i]]);
      continue;
    }
    if (is_inf(exp(lPrZik[i,2]))){
      z[i] = 2;
      Y_pred[i] = normal_rng(mu[z[i]], sigma[z[i]]);
      continue;
    }
    
    z[i] = categorical_rng(exp(lPrZik[i]'));
    
    Y_pred[i] = normal_rng(mu[z[i]], sigma[z[i]]);
  }
}
```

```{r, echo=TRUE, eval=FALSE}
Ex2mod <- stan_model("Ex2.stan")
Ex2fit <- sampling(Ex2mod, data=stan_data, chains=4, iter=4000,
                   control=list("adapt_delta"=0.99))

Ex2samps <- extract(Ex2fit)
plot(density(Ex2samps$Y_pred[Ex2samps$Y_pred>-10 & Ex2samps$Y_pred<100]))
```

```{r echo=FALSE, eval=TRUE}
Ex2fit <- readRDS("/Users/sib2/Box Sync/Faculty/Education/biostat725-sp25/repos/725bayesclust4/fits/Ex2fit.rds")
Ex2samps <- extract(Ex2fit)
```

```{r echo=TRUE, eval=TRUE}
ggplot(data.frame(x1=c(Ex2samps$Y_pred), x2=stan_data$Y)) + 
  geom_density(aes(x=x1), bw=1, color="blue") +
  geom_density(aes(x=x2), bw=1) + 
  ggtitle("Fitted density (blue) + data (black)")
```

```{r echo=TRUE, eval=TRUE}
ggplot(data.frame(x1=c(Ex2samps$Y_pred), x2=stan_data$Y)) + 
  geom_density(aes(x=x1), bw=1, color="blue") +
  geom_density(aes(x=x2), bw=1) + 
  xlim(min(stan_data$Y)-1, max(stan_data$Y)+1) +
  ggtitle("Fitted density (blue) + data (black)", subtitle = "Truncated to sample range")
```

## Exercise 3

Extend the student t mixture model Stan code to simulate data `Y_pred` under the posterior predictive. Compare to the predicted data under the Gaussian mixture model and comment on any similarities/differences.

**Answer:**

Probabilities are better behaved here thanks to the heavy tails. The predictive density has extreme tails (unsurprising given $\nu_1\approx 1.5$). The tails are outlandish in context. However, the mode at $(5,15)$ is better modeled.

```{r}
#| label: ex3

# add code here

```

```{stan eval=FALSE, echo=T, output.var="ex3"}
generated quantities {
  array[n] real Y_pred;
  matrix[n,k] lPrZik;
  
  int<lower=1, upper=k> z[n];
  for (i in 1:n){
    for (h in 1:k){
      lPrZik[i,h] = log(pi[h]) + student_t_lpdf(Y[i] | nu[h], mu[h], sigma[h]);
    }
    lPrZik[i] -= log(sum(exp(lPrZik[i])));
    z[i] = categorical_rng(exp(lPrZik[i]'));
    
    Y_pred[i] = student_t_rng(nu[z[i]], mu[z[i]], sigma[z[i]]);
  }
}
```

```{r, echo=TRUE, eval=FALSE}
Ex3mod <- stan_model("Ex3.stan")
Ex3fit <- sampling(Ex3mod, data=stan_data, chains=4, iter=4000)

Ex3samps <- extract(Ex3fit)
plot(density(Ex3samps$Y_pred[Ex3samps$Y_pred>-10 & Ex3samps$Y_pred<100]))
```

```{r, echo=FALSE, eval=TRUE}
Ex3fit <- readRDS("/Users/sib2/Box Sync/Faculty/Education/biostat725-sp25/repos/725bayesclust4/fits/Ex3fit.rds")
Ex3samps <- extract(Ex3fit)
```

```{r echo=TRUE, eval=TRUE}
ggplot(data.frame(x1=c(Ex3samps$Y_pred), x2=stan_data$Y)) + 
  geom_density(aes(x=x2), bw=1) +
  geom_density(aes(x=x1), bw=1, color="blue") +
  ggtitle("Fitted density (blue) + data (black)")
```

```{r echo=TRUE, eval=TRUE}
ggplot(data.frame(x1=c(Ex3samps$Y_pred), x2=stan_data$Y)) + 
  geom_density(aes(x=x1), bw=1, color="blue") +
  geom_density(aes(x=x2), bw=1) + 
  xlim(min(stan_data$Y)-1, max(stan_data$Y)+1) +
  ggtitle("Fitted density (blue) + data (black)", subtitle = "Truncated to sample range")
```

```{r echo=TRUE, eval=TRUE}
ggplot(data.frame(x1=c(Ex2samps$Y_pred), x2=c(Ex3samps$Y_pred))) + 
  geom_density(aes(x=x1), bw=1, color="red") +
  geom_density(aes(x=x2), bw=1, color="blue") + 
  ggtitle("t-mixture density (blue) + Gaussiam mixture (red)")
```

```{r echo=TRUE, eval=TRUE}
ggplot(data.frame(x1=c(Ex2samps$Y_pred), x2=c(Ex3samps$Y_pred))) + 
  geom_density(aes(x=x1), bw=1, color="red") +
  geom_density(aes(x=x2), bw=1, color="blue") + 
  ggtitle("t-mixture density (blue) + Gaussiam mixture (red)", subtitle = "Truncated to sample range") +
  xlim(min(stan_data$Y)-1, max(stan_data$Y)+1) 
```

::: callout-important
To submit the AE:

-   Render the document to produce the PDF with all of your work from today's class.
-   Push all your work to your AE repo on GitHub. You're done! ðŸŽ‰
:::
