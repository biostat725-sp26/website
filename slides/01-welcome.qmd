---
title: "Welcome to BIOSTAT 725!"
author: "Prof. Sam Berchuck"
date: "2026-01-08"
date-format: "MMM DD, YYYY"
footer: "[ðŸ”— BIOSTAT 725 - Spring 2026](https://biostat725-sp26.netlify.app/)"
logo: "../images/logo.png"
format: 
  revealjs:
    theme: slides.scss
    multiplex: false
    transition: fade
    slide-number: true
    incremental: false 
    chalkboard: true
    html-math-method: mathjax
filters:
  - parse-latex
execute:
  freeze: auto
  echo: true
knitr:
  opts_chunk: 
    R.options:      
    width: 200
bibliography: references.bib
---

```{r, echo=FALSE}
library(ggplot2)
```

# Welcome!

## Meet Prof. Berchuck! {.midi}

::: incremental
-   Education and career journey
    -   BS in Statistical Science from Duke University
    -   PhD in Biostatistics from University of North Carolina - Chapel Hill
    -   Postdoc in Duke Forge: Duke's Center for Actionable Health Data Science
    -   NIH/NEI Pathway to Independence Fellow (K99/R00)
    -   Assistant Professor, Department of Biostatistics & Bioinformatics and Statistical Science at Duke; Faculty Affiliate of Duke AI Health
-   Work focuses on developing data science tools to improve patient experience using biomedical data (including EHR)
-   Dad of 5 and 7 year old daughters ðŸ™‚
:::

------------------------------------------------------------------------

## Teaching Assistants (TAs)

-   Christine Shen
    -   5th year PhD student in the Department of Statistical Science at Duke
-   Jiang Shu
    -   1st year PhD student in the Department of Biostatistics & Bioinformatics at Duke

## Office Hours Poll!

::: question
Click on the link or scan the QR code to answer the poll

<https://forms.office.com/r/QTuhmC0wM3>

<center>

\

![](images/01/qrcode.png){width="25%"}

</center>
:::

## Topics

-   Introduction to the course

-   Syllabus activity

-   Review of probability

# BIOSTAT 725

## What is Bayesian Health Data Science?

<div>

> *Bayesian Health Data Science involves using Bayesian methods to analyze health data, which can include electronic health records (EHR), clinical trial data, and other health-related datasets. These methods are **model-based and can appropriately quantify and propagate uncertainty**, making them suitable for tackling challenges in health research.*

Source: ChatGPT

</div>

## Why Data Science?

::: incremental
-   Statistics versus Data Science?
-   Introductory Bayesian statistics courses are often very mathematical and involve intense computation; thus Bayesian methods are not as frequently used in applied settings.
-   Modern software now exists to lower the mathematical burden and computational intensity of Bayesian statistics, but courses do not reflect this.
-   This course focuses on teaching students Bayesian statistics as a \textcolor{red}{tool} for research; or anywhere data science is practiced.
:::

## What is BIOSTAT 725?

<br>

:::::: columns
::: {.column width="40%"}
<center>

<h2><font color="#993399"> Bayes </font></h2>

Modeling

</center>
:::

::: {.column width="10%"}
<center>

<h2><font color="#993399">+</font></h2>

</center>
:::

::: {.column width="40%"}
<center>

<h2><font color="#993399"> Stan</font></h2>

Probabilistic Programming

</center>
:::
::::::

<br>

**Prerequisites:** BIOSTAT 724 (Introduction to Applied Bayesian Analysis) or equivalent course with instructor permission.

## Course learning objectives {.midi}

By the end of the semester, you will be able to...

-   understand fundamental concepts of Bayesian statistics, including prior and posterior, and predictive distributions,
-   implement the Bayesian workflow, including model building, checking, and refinement,
-   use probabilistic programming software for Bayesian analysis (e.g., Stan),
-   apply Bayesian techniques to real-world health data,
-   communicate Bayesian analysis results effectively to both technical and non-technical audiences, and
-   identify opportunities for using Bayesian statistics in your research and/or job.

## Course topics {.midi}

::::::::: columns
::::: {.column width="48%"}
::: {.fragment fragment-index="1"}
### Linear regression {style="color: #993399"}

-   Methods for inference
-   Prior elicitation
-   Posterior estimation
-   Uncertainty quantification
-   Model assessment
-   Bayesian workflow
-   Prediction
:::

::: {.fragment fragment-index="3"}
### Health Datasets {style="color: #993399"}
:::
:::::

::::: {.column width="48%"}
::: {.fragment fragment-index="2"}
### Extensions {style="color: #993399"}

-   Robust regression
-   Regularization
-   Classification
-   Missing data
:::

::: {.fragment fragment-index="4"}
### Hierarchical Model {style="color: #993399"}

-   Gaussian processes
-   Longitudinal data
-   Spatial data
:::
:::::
:::::::::

# Course overview

## Course toolkit {.midi}

-   **Website**: <https://biostat725-sp26.netlify.app/>
    -   Central hub for the course!
    -   **Tour of the website**
-   **Canvas**: <https://canvas.duke.edu/courses/75433>
    -   Gradebook
    -   Announcements
    -   Gradescope
-   **GitHub:** [github.com/biostat725-sp26](https://github.com/biostat725-sp26)
    -   Distribute assignments
    -   Platform for version control and collaboration

## Computing toolkit {.small}

::::::::: columns
::::: {.column width="50%"}
::: {.fragment fragment-index="1"}
![](images/01/rstudio.png){fig-alt="RStudio logo" fig-align="center" width="5.61in" height="1.6in"}
:::

::: {.fragment fragment-index="2"}
-   All analyses using R, a statistical programming language

-   Inference using Stan, a probabilistic programming language ([rstan](https://mc-stan.org/users/interfaces/rstan))

-   Write reproducible reports in Quarto

-   Access RStudio through [STA725 (STA602) Docker Containers](https://cmgr.oit.duke.edu/containers)
:::
:::::

::::: {.column width="50%"}
::: {.fragment fragment-index="1"}
![](images/01/github.png){fig-alt="GitHub logo" fig-align="center" width="5.61in" height="1.6in"}
:::

::: {.fragment fragment-index="3"}
-   Access assignments

-   Facilitates version control and collaboration

-   All work in [BIOSTAT 725 course organization](https://github.com/biostat725-sp26)
:::
:::::
:::::::::

## Syllabus activity

::: question
1.  Introduce yourself to your group members.
2.  Choose a reporter. This person will share the group's summary with the class.
3.  Read the portion of the syllabus assigned to your group.
4.  Discuss the key points and questions you my have.
5.  The reporter will share a summary with the class.
:::

## Syllabus activity assignments {.midi}

-   Group 1: [What to expect in the course](https://biostat725-sp26.netlify.app/syllabus#what-to-expect-in-the-course)

-   Group 2: [Homework](https://biostat725-sp26.netlify.app/syllabus#homework)

-   Group 3: [Exams](https://biostat725-sp26.netlify.app/syllabus#exams)

-   Group 4: [Live Coding](https://biostat725-sp26.netlify.app/syllabus#live-coding)

-   Group 5: [Application Exercises](https://biostat725-sp26.netlify.app/syllabus#application-exercises)

-   Group 6: [Academic honesty (except AI policy)](https://biostat725-sp26.netlify.app/syllabus#academic-honesty)

-   Group 7: [Artificial intelligence policy](https://biostat725-sp26.netlify.app/syllabus#academic-honesty)

-   Group 8: [Late work policy and waiver for extenuating circumstances](https://biostat725-sp26.netlify.app/syllabus#late-work-policy)

-   Group 9: [Regrade requests and attendance policy](https://biostat725-sp26.netlify.app/syllabus#regrade-requests)

-   Group 10: [Getting help in the course](https://biostat725-sp26.netlify.app/syllabus#getting-help-in-the-course)

## Syllabus activity report out {.midi}

::: incremental
-   Group 1: [What to expect in the course](https://biostat725-sp26.netlify.app/syllabus#what-to-expect-in-the-course)

-   Group 2: [Homework](https://biostat725-sp26.netlify.app/syllabus#homework)

-   Group 3: [Exams](https://biostat725-sp26.netlify.app/syllabus#exams)

-   Group 4: [Live Coding](https://biostat725-sp26.netlify.app/syllabus#live-coding)

-   Group 5: [Application Exercises](https://biostat725-sp26.netlify.app/syllabus#application-exercises)

-   Group 6: [Academic honesty (except AI policy)](https://biostat725-sp26.netlify.app/syllabus#academic-honesty)

-   Group 7: [Artificial intelligence policy](https://biostat725-sp26.netlify.app/syllabus#academic-honesty)

-   Group 8: [Late work policy and waiver for extenuating circumstances](https://biostat725-sp26.netlify.app/syllabus#late-work-policy)

-   Group 9: [Regrade requests and attendance policy](https://biostat725-sp26.netlify.app/syllabus#regrade-requests)

-   Group 10: [Getting help in the course](https://biostat725-sp26.netlify.app/syllabus#getting-help-in-the-course)
:::

## Grading

| Category              | Percentage |
|-----------------------|------------|
| Homework              | 40%        |
| Exam 01               | 20%        |
| Exam 02               | 20%        |
| Live Coding           | 10%        |
| Application Exercises | 10%        |
| Total                 | 100%       |

## Five tips for success in BIOSTAT 725

1.  Complete all the preparation work before class.

2.  Ask questions in class, and office hours.

3.  Do the homework; get started on homework early when possible.

4.  Don't procrastinate and don't let a week pass by with lingering questions.

5.  Stay up-to-date on announcements on Canvas and sent via email.

# Probability

This is foundational material that you should have already learned in a previous course. I'm reviewing important concepts that are needed for Bayesian inference.

## Review of probability

-   The goal of Bayesian statistics is to compute the posterior distribution (i.e., the uncertainty distribution of the parameters, $\boldsymbol{\theta}$, after observing the data, $\mathbf{Y}$).

-   This is the conditional distribution of $\boldsymbol{\theta}$ given $\mathbf{Y}$.

-   Therefore, we need to review the probability concepts that lead to the conditional distribution of one variable conditioned on another.

    1.  Probability mass (pmf) and density (pdf) functions

    2.  Joint distributions

    3.  Marginal and conditional distributions

## Random variables

-   $X$ (capital) is a random variable.

-   We want to compute the probability that $X$ takes on a specific value $x$ (lowercase).

    -   This is denoted $P(X = x)$.

-   We also might want to compute the probability of $X$ being in a set $\mathcal A$.

    -   This is denoted $P(X \in \mathcal A)$.

-   The set of possible values that $X$ can take on is called its support, $\mathcal S$.

## Random variables - example

-   Example 1: $X$ is the roll of a die.

    -   The support is $\mathcal S = \{1, 2, 3, 4, 5, 6\}$.
    -   $P(X = 1) = 1/6$.

-   Example 2: $X$ is a newborn babyâ€™s weight.

    -   The support is $\mathcal S = (0, \infty)$.
    -   $P(X \in [0, \infty]) = 1$.

<!-- ## Axioms of probability -->

<!-- For two events $A$ and $B$, -->

<!-- A1. Probabilities are between 0 and 1, importantly $P(A^c | A) = 0$ and $P(A | A) = 1$. -->

<!-- A2. If $A$ and $B$ are disjoint, then $P(A\text{ or }B) = P(A) + P(B)$. -->

<!-- A3. The joint probability of two events may be broken down stepwise: $P(A,B) = P(A | B)P(B)$. -->

<!-- ## Consequences of probability axioms -->

<!-- -   For any partition $\{H_i\}_{i = 1}^n$, $\sum_{i=1}^n P(H_i) = 1$ (rule of total probability) -->

<!--     -   Note: simplest partition $P(A) + P(A^c) = 1$ -->

<!-- -   $P(A) = \sum_{i=1}^n P(A, H_i)$ (rule of marginal probability) -->

<!--     -   Note: A3 implies that equivalently, $P(A) = \sum_{i=1}^n P(A | H_i) P(H_i)$ -->

<!-- -   $P(A | B) = P(A,B) / P(B)$ when $P(B) \neq 0$ -->

<!--     -   Note: these statements can also be made where each term is additionally conditioned on another event $C$ -->

## What is probability?

Objective (associated with frequentist)

-   $P(X = x)$ as a purely mathematical statement.
-   If we repeatedly sampled $X$, then the proportion of draws equal to $x$ converges to $P(X = x)$.

Subjective (associated with Bayesian)

-   $P(X = x)$ represents an individualâ€™s degree of belief.
-   Often quantified as the amount an individual would be willing to wager that $X$ will be $x$.

A Bayesian analysis makes use of both of these concepts.

## What is uncertainty?

Aleatoric uncertainty (likelihood)

-   Uncontrollable randomness in the experiment.

-   For example, the results of a fair coin flip can never be predicted with certainty.

Epistemic uncertainty (prior/posterior)

-   Uncertainty about a quantity that could theoretically be known.

-   For example, if we flipped a coin infinitely-many times we could know the true probability of a head.

A Bayesian analysis makes use of both of these concepts.

<!-- ## Probability versus statistics -->

<!-- Probability is the forward problem -->

<!-- -   We assume we know how the data are being generated and compute the probability of events -->

<!-- -   For example, what is the probability of flipping 5 straight heads if the coin is fair? -->

<!-- Statistics is the inverse problem -->

<!-- -   We use data to learn about the data-generating mechanism -->

<!-- -   For example, if we flipped five straight head, can we conclude the coin is biased? -->

<!-- Any statistical analysis obviously relies on probability -->

## Univariate distributions

-   We often distinguish between discrete and continuous random variables.

-   The random variable $X$ is **discrete** if its support $\mathcal S$ is countable.

-   Examples:

$X \in \{0, 1, 2, 3\}$ is the number of successes in 3 trials.

$X \in \{0, 1, 2, \ldots\}$ is the number of patients with COVID in Durham County.

## Univariate distributions

-   We often distinguish between discrete and continuous random variables.

-   The random variable $X$ is **continuous** if its support $\mathcal S$ is uncountable.

-   Examples with $\mathcal S = (0, \infty)$:

$X > 0$ is systolic blood pressure.

$X > 0$ is a patient's BMI.

## Discrete univariate distributions

-   If $X$ is discrete we describe its distribution with its **probability mass function (pmf)**.

-   The pmf is $f(x) = P(X = x)$.

-   The domain of $X$ is the set of $x$ with $f(x) > 0$.

-   We must have $f(x) \geq 0$ and $\sum_x f(x) = 1$.

-   The mean is $\mathbb E[X] = \sum_x x f(x)$.

-   The variance is $\mathbb V(X) = \sum_x(x âˆ’ \mathbb E[X])^2f(x)$.

-   The last three sums are over $X$â€™s domain.

## Parametric families of distributions

-   A statistical analysis typically proceeds by selecting a pmf that seems to match the distribution of a sample.

-   We rarely know the pmf exactly, but we assume it is from a parametric family of distributions.

-   For example, Binomial(10, 0.5) and Binomial(4, 0.1) are different but both from the binomial family.

-   A family of distributions have the same equation for the pmf but differ by some unknown parameters $\boldsymbol{\theta}$.

-   We must estimate these parameters.

## Continuous univariate distributions {.midi}

-   If $X$ is continuous we describe its distribution with the **probability density function (pdf)** $f(x) \geq 0$.

-   Since there are uncountably many possible values, $P(X = x) = 0$ for all $x$.

-   Probabilities are computed as areas under the pdf curve $$P(a < X < b) = \int_a^b f(x)dx.$$

-   Therefore, to be valid $f(x)$ must satisfy $f(x) \geq 0$ and $$P(âˆ’\infty < X < \infty) = \int_{-\infty}^{\infty} f(x)dx = 1.$$

## Continuous univariate distributions

-   The domain is the set of $x$ values with $f(x) > 0$.

-   The mean and the variance are defined similarly to the discrete case but with the sums replaced by integrals.

-   The mean is $\mathbb E[X] = \int x f(x)dx$.

-   The variance is $\mathbb V(X) = \int (x âˆ’ \mathbb E[X])^2 f(x)dx$.

## Joint distributions

-   $\mathbf{X} = (X_1, \ldots, X_p)$ is a random vector (vectors and matrices should be in bold).

-   For notational convenience, letâ€™s consider only $p = 2$ random variables $X$ and $Y$.

-   $(X, Y)$ is discrete if it can take on a countable number of values, such as:

    -   $X$ = number of hearts and $Y$ = number of face cards.

-   $(X, Y)$ is continuous if it can take on an uncountable number of values, such as:

    -   $X$ = birthweight and $Y$ = gestational age.

## Discrete random variables

-   The **joint pmf**: $f(x, y) = P(X = x, Y = y)$

    -   $\sum_x \sum_y f(x, y) = 1$

-   The **marginal pmf** for $X$: $f_X(x) = P(X = x) = \sum_y f(x, y)$

-   The **marginal pmf** for $Y$: $f_Y(y) = P(Y = y) = \sum_x f(x, y)$

-   The marginal distribution is the same as univariate distribution as if we ignored the other variable.

## Discrete random variables

-   The **conditional pmf** of $Y$ given $X$ is $f(y|x) = P(Y = y|X = x) = \frac{P(X = x, Y = y)}{P(X = x)} = \frac{f(x, y)}{f_X (x)}.$

-   $X$ and $Y$ are **independent** if $f(x, y) = f_X(x)f_Y(y)$ for all $x$ and $y$.

    -   Variables are dependent if they are not independent.

-   Equivalently, $X$ and $Y$ are independent if $f(x|y) = f_X(x)$ for all $x$ and $y$.

## Discrete random variables

-   Notation: $X_1, \dots, X_n \overset{\mathrm{iid}}{\sim} f(x)$ means that $X_1, \ldots, X_n$ are independent and identically distributed.

-   This implies the **joint pmf** is $$P(X_1 = x_1, \ldots, X_n = x_n) = \prod_{i=1}^n f(x_i).$$

-   The same notation and definitions of independence apply to continuous random variables.

-   In this class, assume independence unless otherwise noted.

## Continuous random variables

-   Manipulating joint pdfs is similar to joint pmfs but sums are replaced by integrals.

-   The **joint pdf** is denoted $f(x, y)$.

-   Probabilities are computed as volume under the pdf: $$P((X, Y) âˆˆ A) = \int_A f(x, y)dxdy$$ where $A \subset \mathbb{R}^2$.

## Continuous random variables

-   The **marginal pdf** of $X$ is $f_X(x) = \int f(x, y)dy$.

-   $f_X$ is the univariate pdf for $X$ as if we never considered $Y$.

-   The **conditional pdf** of $Y$ given $X$ is $$f(y|x) = \frac{f(x, y)}{f_X (x)}.$$

-   Proper: $\int f(y|x)dy = \int \frac{f(x,y)}{f_X(x)}dy = \frac{\int f(x,y)dy}{f_X(x)} = 1$.

## Defining joint distributions conditionally

-   Specifying joint distributions is hard.

-   Every joint distribution can be written $f(x, y) = f(y|x)f(x)$.

-   Therefore, any joint distribution can be defined by,

    1.  $X$â€™s marginal distribution

    2.  The conditional distribution of $Y|X$

-   The joint problem reduces to two univariate problems.

-   This idea forms the basis of hierarchical modeling.

<!-- ## Review: Set theory {.small} -->

<!-- ::: callout-note -->

<!-- ## Definition -->

<!-- **set**: a collection of elements, denoted by {} -->

<!-- Examples -->

<!-- -   $\phi$ = {} "the empty set" -->

<!-- -   $A$ = {1, 2, 3} -->

<!-- -   $B$ = {taken BIOSTAT 724, has not taken BIOSTAT 724} -->

<!-- -   $C$ = {{1,2,3}, {4, 5}} -->

<!-- ::: -->

<!-- ::: callout-note -->

<!-- ## Definition -->

<!-- **subset**: denoted by $\subset$, $A \subset B$ iff -->

<!-- $a \in A \implies a \in B$ -->

<!-- Examples -->

<!-- Using the previously examples of $A$, $B$ and $C$ above, -->

<!-- -   $A \subset C$ -->

<!-- -   $A \not\subset B$ -->

<!-- ::: -->

<!-- Recall: $\cup$ means "union", "or"; $\cap$ means "intersection", "and" -->

<!-- ## Review: Set theory {.small} -->

<!-- ::: callout-note -->

<!-- ## Definition -->

<!-- **partition**: {$H_1, H_2, ... H_n$} = $\{H_i\}_{i = 1}^n$ is a -->

<!-- partition of $\mathcal{H}$ if -->

<!-- 1.  the union of sets is $\mathcal{H}$ i.e., -->

<!--     $\cup_{i = 1}^n H_i = \mathcal{H}$ -->

<!-- 2.  the sets are disjoint i.e., $H_i \cap H_j = \phi$ for all $i \neq j$ -->

<!-- ::: -->

<!-- ::: callout-note -->

<!-- ## Definition -->

<!-- **sample space**: $\mathcal{H}$, the set of all possible data sets -->

<!-- (outcomes) -->

<!-- **event**: a set of one or more outcomes -->

<!-- Note: p($\mathcal{H}$) = 1 -->

<!-- Examples -->

<!-- -   Roll a six-sided die once. The sample space -->

<!--     $\mathcal{H} = \{1, 2, 3, 4, 5, 6\}$. -->

<!-- -   Let $A$ be the event that the die lands on an even number. -->

<!--     $A = \{2, 4, 6 \}$ -->

<!-- ::: -->

## Bayes rule {.midi}

:::::: columns
::: {.column width="10%"}
:::

::: {.column width="45%"}
![](images/01/bayes.png){fig-align="center" height="300"}\
Thomas Bayes, 1701-1761
:::

::: {.column width="45%"}
![](images/01/laplace.png){fig-align="center" height="300"}\
Pierre-Simon Laplace, 1749-1827
:::
::::::

$$f(\boldsymbol{\theta}|\mathbf{Y}) = \frac{f(\mathbf{Y}|\boldsymbol{\theta})f(\boldsymbol{\theta})}{\int f(\mathbf{Y}|\boldsymbol{\theta})f(\boldsymbol{\theta})d\boldsymbol{\theta}}$$

<!-- ## The Table Game -->

<!-- ![](images/01/bayesproblem.png){fig-align="center" height="300"}\ -->

<!-- ## Translation -->

## Prepare for next week

-   Complete [HW 00 tasks](https://biostat725-sp26.netlify.app/hw/hw-00)

-   Review [syllabus](https://biostat725-sp26.netlify.app/syllabus)

-   Complete reading to prepare for Tuesday's lecture

-   Tuesday's lecture: Monte Carlo Sampling
