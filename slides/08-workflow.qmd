---
title: "Bayesian Workflow"
author: "Prof. Sam Berchuck"
date: "2026-02-03"
date-format: "MMM DD, YYYY"
footer: "[ðŸ”— BIOSTAT 725 - Spring 2026](https://biostat725-sp26.netlify.app/)"
logo: "../images/logo.png"
format: 
  revealjs:
    theme: slides.scss
    multiplex: false
    transition: fade
    slide-number: true
    incremental: false 
    chalkboard: true
    html-math-method: mathjax
filters:
  - parse-latex
execute:
  freeze: auto
  echo: true
knitr:
  opts_chunk: 
    R.options:      
    width: 200
bibliography: references.bib
---

```{r, echo=FALSE}
library(tidyverse)
library(ggplot2)
library(gridExtra)
library(knitr)
library(mvtnorm)
library(coda)
```

## Review of last lecture

On Thursday, we learned about various ways compare models.

-   AIC, DIC, WAIC

-   LOO-CV/LOO-IC

Today, we will put these concepts within the larger framework of the Bayesian workflow.

## Bayes theorem

$$f(\boldsymbol{\theta} | \mathbf{Y}) = \frac{f(\mathbf{Y} | \boldsymbol{\theta})f(\boldsymbol{\theta})}{f(\mathbf{Y})}$$

. . .

-   Rethinking Bayes theorem:

$$f(\boldsymbol{\theta} | \mathbf{Y}) \propto f(\mathbf{Y}, \boldsymbol{\theta}) = f(\mathbf{Y} | \boldsymbol{\theta})f(\boldsymbol{\theta}) $$

. . .

-   In Stan:

$$\log f(\mathbf{Y} | \boldsymbol{\theta}) + \log f(\boldsymbol{\theta})$$

<!-- ## Bayesian statistics -->

<!-- Advantages: -->

<!-- - Natural approach to expressing uncertainty -->

<!-- - Ability to incorporate prior information -->

<!-- - Increased modeling flexibility -->

<!-- - Full posterior distribution of parameters -->

<!-- - Natural propagation of uncertainty -->

<!-- Disadvantages: -->

<!-- - Slow speed of model estimation -->

## Bayesian workflow {.smaller}

![](images/07/workflow.png){fig-alt="workflow" fig-align="center" height="5in"}

[Gelman A., Vehtari A., Simpson D., Margossian, C., Carpenter, B. and Yao, Y., Kennedy, L., Gabry, J., BÃ¼rkner P. C., & ModrÃ¡k M. (2020). Bayesian Workflow.](https://arxiv.org/abs/2011.01808)

## Bayesian workflow

![[Taken from Bayesian workflow by Francesca Capel](https://francescacapel.com/BayesianWorkflow/index.html)](images/07/workflow0.png){fig-alt="workflow0" fig-align="center" height="4in"}

-   Today we will talk about a general strategy for taking a question and data to a robust conclusion.

## A simplified workflow {.midi}

1.  *Setting up a full probability model:* a joint probability distribution for all observable and unobservable quantities in a problem. The model should be consistent with knowledge about the underlying scientific problem and the data collection process.

2.  *Conditioning on observed data:* calculating and interpreting the appropriate posterior distribution â€” the conditional probability distribution of the unobserved quantities of ultimate interest, given the observed data.

3.  *Evaluating the fit of the model and the implications of the resulting posterior distribution:* how well does the model fit the data, are the substantive conclusions reasonable, and how sensitive are the results to the modeling assumptions in step 1? In response, one can alter or expand the model and repeat the three steps.

From [BDA3](http://www.stat.columbia.edu/~gelman/book/).

## Bayesian workflow

1.  **Research question:** What are your dependent and indepednent variables? What associations are you interested in? EDA.

. . .

2.  **Specify likelihood & priors:** Use knowledge of the problem to construct a generative model.

. . .

3.  **Check the model with simulated data:** Generate data from the model and evaluate fit as a sanity check (prior predictive checks).

. . .

4.  **Fit the model to real data:** Estimate parameters using MCMC.

## Bayesian workflow

5.  **Check diagnostics:** Use MCMC diagnostics to guarentee that the algorithm converged.

. . .

6.  **Examine posterior fit:** Create posterior summaries that are relevant to the research question.

. . .

7.  **Check predictions:** Examing posterior predictive checks.

. . .

8.  **Compare models:** Iterate on model design and choose a model.

## Motivating example: predicting weight from height {.midi}

**Research question:** We would like to understand the relationship between a person's height and weight. A few particular questions we have are:

1.  How much does a person's weight increase when their height increases?

2.  How certain can we be about the magnitude of the increase?

3.  Can we predict a personâ€™s weight based on their height?

**Data:** We will use the `bdims` dataset from the `openintro` package. This dataset contains body girth measurements and skeletal diameter measurements, as well as age, weight, height and gender.

## Prepare data

```{r}
library(openintro)
dat <- data.frame(weight = bdims$wgt * 2.20462, # convert weight to lbs
                  height = bdims$hgt * 0.393701, # convert height to inches
                  sex = ifelse(bdims$sex == 1, "Male", "Female"))
head(dat)
```

## 1. **Research question:**

```{r}
#| echo: false
#| fig-align: "center"
#| fig-width: 4
#| fig-height: 4
#| layout-ncol: 2
dat |> ggplot(aes(weight)) + 
  geom_histogram() + 
  labs(x = "Weight (pounds)", y = "Count")
dat |> ggplot(aes(height)) + 
  geom_histogram() + 
  labs(x = "Height (inches)", y = "Count")
```

## 1. **Research question:**

```{r}
#| echo: false
#| fig-align: "center"
#| fig-width: 5
#| fig-height: 4
#| layout-ncol: 2
dat |> ggplot(aes(x = weight, fill = sex)) + 
  geom_histogram() + 
  labs(x = "Weight (pounds)", y = "Count")
dat |> ggplot(aes(x = height, fill = sex)) + 
  geom_histogram() + 
  labs(x = "Height (inches)", y = "Count")
```

## 1. **Research question:**

```{r}
#| echo: false
#| fig-align: "center"
#| fig-width: 5
#| fig-height: 4
#| layout-ncol: 1
dat |> ggplot(aes(y = weight, x = height, col = sex)) + 
  geom_point() + 
  labs(x = "Height (inches)", y = "Weight (pounds)", y = "Count")
```

## 2. **Specify likelihood & priors:** {.midi}

-   Construct a data generating process.

-   We would like to model weight as a function of height using a linear regression model.

-   Define, $Y_i$ as the weight of observation $i$ and $\mathbf{x}_i$ as a vector of covariates (here only height).

$$Y_i = \alpha + \mathbf{x}_i\boldsymbol{\beta} + \epsilon_i,\quad \epsilon_i \sim N(0,\sigma^2)$$

```{stan output.var = "workflow", eval = FALSE}
data {
  int<lower = 1> n; // number of observations
  int<lower = 1> p; // number of covariates (excluding intercept)
  vector[n] Y;      // outcome variable
  matrix[n, p] X;   // covariate matrix
}
```

## 2. **Specify likelihood & priors:**

-   Construct a data generating process.

-   We would like to model weight as a function of height using a linear regression model.

$$Y_i = \alpha + \mathbf{x}_i\boldsymbol{\beta} + \epsilon_i,\quad \epsilon_i \sim N(0,\sigma^2)$$

```{stan output.var = "workflow", eval = FALSE}
parameter {
  real alpha;            // intercept on the original scale
  vector[p] beta;        // regression parameters
  real<lower = 0> sigma; // measurement error
}
```

## 2. **Specify likelihood & priors:**

-   Construct a data generating process.

-   We would like to model weight as a function of height using a linear regression model.

$$Y_i = \alpha + \mathbf{x}_i\boldsymbol{\beta} + \epsilon_i,\quad \epsilon_i \sim N(0,\sigma^2)$$

```{stan output.var = "workflow", eval = FALSE}
model {
  target += normal_lpdf(Y | alpha + X * beta, sigma);
}
```

## 2. **Specify likelihood & priors:** {.midi}

$$Y_i = \alpha + \mathbf{x}_i\boldsymbol{\beta} + \epsilon_i,\quad \epsilon_i \sim N(0,\sigma^2)$$

Think about reasonable priors for your parameters:

-   $\alpha$ is the intercept, or average weight for someone who is zero inches (not a particularly useful number on its own)

-   $\beta$ measures the association between weight and height, in pounds/inch

-   $\sigma$ is the measurement error for the population

```{stan output.var = "workflow", eval = FALSE}
model {
  target += normal_lpdf(Y | alpha + X * beta, sigma);
  target += normal_lpdf(alpha | 0, 10);
  target += normal_lpdf(beta | 0, 10);
  sigma ~ normal(0, 10);
}
```

## 2. **Specify likelihood & priors:** {.midi}

$$\mathbb{E}[Y_i] = \alpha^+ + (\mathbf{x}_i - \bar{\mathbf{x}}) \boldsymbol{\beta},\quad\bar{\mathbf{x}}=\frac{1}{n}\sum_{i=1}^n \mathbf{x}_i$$

Think about reasonable priors for your parameters:

-   $\alpha^+$ is the intercept, or average weight for someone who is an average height

```{stan output.var = "workflow", eval = FALSE}
transformed data {
  matrix[n, p] X_centered;
  row_vector[p] X_bar;
  for (i in 1:p) {
    X_bar[i] = mean(X[, i]);
    X_centered[, i] = X[, i] - X_bar[i];
  }
}
```

## 2. **Specify likelihood & priors:** {.midi}

$$\mathbb{E}[Y_i] = \alpha^+ + (\mathbf{x}_i - \bar{\mathbf{x}}) \boldsymbol{\beta},\quad\bar{\mathbf{x}}=\frac{1}{n}\sum_{i=1}^n \mathbf{x}_i$$

Think about reasonable priors for your parameters:

-   $\alpha^+$ is the intercept, or average weight for someone who is an average height

```{stan output.var = "workflow", eval = FALSE}
model {
  target += normal_lpdf(Y | alpha_plus + X_centered * beta, sigma);
  target += normal_lpdf(alpha_plus | 150, 10);
  target += normal_lpdf(beta | 0, 10);
  sigma ~ normal(0, 10);
}
```

-   Hard to put a weakly informative prior on $\alpha^+$.

## 2. **Specify likelihood & priors:** {.small}

$$\mathbb{E}[Y_i - \bar{Y}] = \alpha^* + (\mathbf{x}_i - \bar{\mathbf{x}}) \boldsymbol{\beta},\quad\bar{Y}=\frac{1}{n}\sum_{i=1}^n Y_i$$

Think about reasonable priors for your parameters:

-   $\alpha^*$ is the intercept for the centered data, should be zero.

```{stan output.var = "workflow", eval = FALSE}
transformed data {
  vector[n] Y_centered;
  real Y_bar;
  matrix[n, p] X_centered;
  row_vector[p] X_bar;
  for (i in 1:p) {
    X_bar[i] = mean(X[, i]);
    X_centered[, i] = X[, i] - X_bar[i];
  }
  Y_bar = mean(Y);
  Y_centered = Y - Y_bar;
}
```

## 2. **Specify likelihood & priors:** {.small}

$$\mathbb{E}[Y_i - \bar{Y}] = \alpha^* + (\mathbf{x}_i - \bar{\mathbf{x}}) \boldsymbol{\beta},\quad\bar{Y}=\frac{1}{n}\sum_{i=1}^n Y_i$$

Think about reasonable priors for your parameters:

-   $\alpha^*$ is the intercept for the centered data, should be zero.

```{stan output.var = "workflow", eval = FALSE}
model {
  target += normal_lpdf(Y_centered | alpha_star + X_centered * beta, sigma);
  target += normal_lpdf(alpha_star | 0, 10);
  target += normal_lpdf(beta | 0, 10);
  sigma ~ normal(0, 10);
}
```

## Quick aside

What does it mean to use the prior `sigma ~ normal(0, 10)`?

-   When a parameter is truncated, for example `real<lower = 0> sigma`, priors can still be placed across the real line, $\mathbb{R}$.

```{stan output.var = "workflow", eval = FALSE}
parameters {
  real<lower = 0> sigma;
}
model {
  sigma ~ normal(0, 10);
}
```

-   This specification induces a prior on the truncated space $\mathbb{R}^+$.

-   The induced prior for `sigma` is a [half-normal distribution](https://en.wikipedia.org/wiki/Half-normal_distribution).

## Quick aside

-   The half-normal is a useful prior for nonnegative parameters that should not be too large and may be very close to zero.

-   Similar distributions for scale parameters are [half-t](https://en.wikipedia.org/wiki/Folded-t_and_half-t_distributions) and [half-Cauchy](https://distribution-explorer.github.io/continuous/halfcauchy.html) priors, these have heavier tales.

```{r}
#| echo: false
#| fig-align: "center"
#| fig-width: 6
#| fig-height: 3
#| layout-ncol: 1
library(LaplacesDemon)
library(reshape2)
x <- seq(0.001, 10, length.out = 501)
norm <- LaplacesDemon::dhalfnorm(x, 1)
ig <- pscl::densigamma(x, 3, 1)
temp <- data.frame(x = x, normal = norm, inverse_gamma = ig)
dat.fig <- melt(temp, id.vars = "x", variable.name = "distribution")
levels(dat.fig$distribution) <- c("Half-normal(1)", "Inverse-gamma(3, 1)")
dat.fig |> ggplot(aes(x = x, y = value, color = distribution)) + 
  geom_line(lwd = 1.5) + 
  labs(x = expression(sigma), y = "Density", color = "Distribution")
```

## 3. **Check the model with simulated data:**

1.  Draw parameter values from priors.

2.  Generate data based on those parameter values.

3.  Check simulated data summaries and compare to observed data.

## 3. **Check the model with simulated data:** {.small}

```{stan output.var = "workflow", eval = FALSE}
// stored in workflow_prior_pred_check.stan
data {
  int<lower = 1> n;
  int<lower = 1> p;
  real Y_bar;
  matrix[n, p] X;
  real<lower = 0> sigma_alpha;
  real<lower = 0> sigma_beta;
  real<lower = 0> sigma_sigma;
}
transformed data {
  row_vector[p] X_bar;
  for (i in 1:p) X_bar[i] = mean(X[, i]);
}
generated quantities {
  // Sample from the priors
  real alpha_star = normal_rng(0, sigma_alpha);
  real alpha_plus = alpha_star + Y_bar;
  real alpha = alpha_plus - X_bar * beta;
  vector[p] beta;
  for (i in 1:p) beta[i] = normal_rng(0, sigma_beta);
  real sigma = fabs(normal_rng(0, sigma_sigma));
  // Simulate data from the prior
  vector[n] Y;
  for (i in 1:n) {
    Y[i] = normal_rng(alpha + X[i, ] * beta, sigma);
  }
  // Compute summaries from the prior
  real Y_min = min(Y);
  real Y_max = max(Y);
  real Y_mean = mean(Y);
}
```

## 3. **Check the model with simulated data:** {.small}

```{r, eval = FALSE}
###Compile the Stan code
prior_check <- stan_model(file = "workflow_prior_pred_check.stan")

###Define the Stan data object
Y <- dat$weight
X <- matrix(dat$height)
stan_data <- list(
  n = nrow(dat), 
  p = ncol(X),
  Y_bar = mean(Y),
  X = X,
  sigma_alpha = 10,
  sigma_beta = 10,
  sigma_sigma = 10)

###Simulate data from the prior
prior_check1 <- sampling(prior_check, data = stan_data, 
                         algorithm = "Fixed_param", chains = 1, iter = 1000)
```

## 3. **Check the model with simulated data:**

```{r, eval = FALSE, echo = FALSE}
Y_sums <- rstan::extract(prior_pc_bad, pars = c("Y_mean", "Y_min", "Y_max"))
dat_fig <- data.frame(
  value = unlist(Y_sums),
  type = rep(c("Mean", "Min", "Max"), each = 500)
)
ggplot(dat_fig, aes(x = value)) + 
  geom_histogram() + 
  facet_grid(. ~ type, scales = "free_x") + 
  labs(x = "Value of each summary",
       y = "Count",
       title = "Prior Predictive Checks",
       subtitle = "Summaries computed in data simulated from the prior")
```

```{r}
#| echo: false
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4
#| layout-ncol: 1
prior_pc_bad <- readRDS(file = "/Users/sib2/Box Sync/Faculty/Education/biostat725-sp25/course-material/r-objects/workflow_prior_pc_bad.RDS")
Y_sums <- rstan::extract(prior_pc_bad, pars = c("Y_mean", "Y_min", "Y_max"))
dat_fig <- data.frame(
  value = unlist(Y_sums),
  type = rep(c("Mean", "Min", "Max"), each = 500)
)
ggplot(dat_fig, aes(x = value)) + 
  geom_histogram() + 
  facet_grid(. ~ type, scales = "free_x") + 
  labs(x = "Value of each summary",
       y = "Count",
       title = "Prior Predictive Checks",
       subtitle = "Summaries computed in data simulated from the prior")
```

## 3. **Check the model with simulated data:** {.small}

```{r, eval = FALSE}
###Compile the Stan code
prior_check <- stan_model(file = "workflow_prior_pred_check.stan")

###Define the Stan data object
Y <- dat$weight
X <- matrix(dat$height)
stan_data <- list(
  n = nrow(dat), 
  p = ncol(X),
  Y_bar = mean(Y),
  X = X,
  sigma_alpha = 10,
  sigma_beta = 5,
  sigma_sigma = 4)

###Simulate data from the prior
prior_check2 <- sampling(prior_check, data = stan_data, 
                         algorithm = "Fixed_param", chains = 1, iter = 1000)
```

## 3. **Check the model with simulated data:**

```{r}
#| echo: false
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4
#| layout-ncol: 1
prior_pc_better <- readRDS(file = "/Users/sib2/Box Sync/Faculty/Education/biostat725-sp25/course-material/r-objects/workflow_prior_pc_better.rds")
Y_sums <- rstan::extract(prior_pc_better, pars = c("Y_mean", "Y_min", "Y_max"))
dat_fig <- data.frame(
  value = unlist(Y_sums),
  type = rep(c("Mean", "Min", "Max"), each = 500)
)
ggplot(dat_fig, aes(x = value)) + 
  geom_histogram() + 
  facet_grid(. ~ type, scales = "free_x") + 
  labs(x = "Value of each summary",
       y = "Count",
       title = "Prior Predictive Checks: Update scales",
       subtitle = "Summaries computed in data simulated from the prior")
```

## 4. **Fit the model to real data:** {.midi}

```{stan output.var = "workflow", eval = FALSE}
// saved in linear_regression_workflow.stan
data {
  int<lower = 1> n;        // number of observations
  int<lower = 1> p;        // number of covariates (excluding intercept)
  vector[n] Y;             // outcome vector
  matrix[n, p] X;          // covariate matrix
  int<lower = 1> n_pred;   // number of new observations to predict
  matrix[n_pred, p] X_new; // covariate matrix for new observations
}
transformed data {
  vector[n] Y_centered;
  real Y_bar;
  matrix[n, p] X_centered;
  row_vector[p] X_bar;
  for (i in 1:p) {
    X_bar[i] = mean(X[, i]);
    X_centered[, i] = X[, i] - X_bar[i];
  }
  Y_bar = mean(Y);
  Y_centered = Y - Y_bar;
}
parameters {
  real alpha_star;
  vector[p] beta;
  real<lower = 0> sigma;
}
model {
  target += normal_lpdf(Y_centered | alpha_star + X_centered * beta, sigma); // likelihood
  target += normal_lpdf(alpha_star | 0, 10);
  target += normal_lpdf(beta | 0, 5);
  sigma ~ normal(0, 4);
}
generated quantities {
  vector[n] Y_pred;
  vector[n] log_lik;
  vector[n_pred] Y_new;
  real alpha = Y_bar + alpha_star - X_bar * beta;
  for (i in 1:n) {
    Y_pred[i] = normal_rng(alpha + X[i, ] * beta, sigma);
    log_lik[i] = normal_lpdf(Y_centered[i] | alpha_star + X_centered[i, ] * beta, sigma);
  }
  for (i in 1:n_pred) Y_new[i] = normal_rng(alpha + X_new[i, ] * beta, sigma);
}
```

## 4. **Fit the model to real data:** {.midi}

```{r, eval = FALSE, echo = FALSE}
dat <- data.frame(weight = bdims$wgt * 2.20462,
                  height = bdims$hgt * 0.393701,
                  sex = bdims$sex)
X <- matrix(dat$height)
n_new <- 1000
X_new <- matrix(seq(min(dat$height), max(dat$height), length.out = n_new))
stan_data <- list(
  n = nrow(dat), 
  p = ncol(X),
  Y = dat$weight,
  X = X,
  n_new = n_new,
  X_new = X_new
)
compiled_model <- stan_model(file = "/Users/sib2/Box Sync/Faculty/Education/biostat725-sp25/course-material/r-objects/linear_regression_workflow.stan")
fit_workflow <- sampling(compiled_model, data = stan_data)
saveRDS(fit_workflow, file = "/Users/sib2/Box Sync/Faculty/Education/biostat725-sp25/course-material/r-objects/fit_workflow.RDS")
```

```{r, eval = FALSE}
###Compile model
regression_model <- stan_model(file = "linear_regression_workflow.stan")

###Create data
Y <- dat$weight
X <- matrix(dat$height)
n_new <- 1000
X_new <- matrix(seq(min(dat$height), max(dat$height), length.out = n_new))
stan_data <- list(
  n = nrow(dat), 
  p = ncol(X),
  Y = Y,
  X = X,
  n_new = n_new,
  X_new = X_new
)
```

## 4. **Fit the model to real data:** {.midi}

```{r, eval = FALSE}
###Fit the model
fit_workflow <- sampling(regression_model, data = stan_data)
print(fit_workflow, pars = c("alpha", "beta", "sigma"), probs = c(0.025, 0.5, 0.975))
```

```{r, echo = FALSE}
###Create data
Y <- dat$weight
X <- matrix(dat$height)
n_new <- 1000
X_new <- matrix(seq(min(dat$height), max(dat$height), length.out = n_new))
stan_data <- list(
  n = nrow(dat), 
  p = ncol(X),
  Y = dat$weight,
  X = X,
  n_new = n_new,
  X_new = X_new
)
fit_workflow <- readRDS(file = "/Users/sib2/Box Sync/Faculty/Education/biostat725-sp25/course-material/r-objects/fit_workflow.RDS")
print(fit_workflow, pars = c("alpha", "beta", "sigma"), probs = c(0.025, 0.5, 0.975))
```

## 5. **Check diagnostics:**

```{r}
rstan::traceplot(fit_workflow, pars = c("alpha", "beta", "sigma"))
```

## 5. **Check diagnostics:**

```{r}
library(bayesplot)
mcmc_acf(fit_workflow, regex_pars = c("alpha", "beta", "sigma"))
```

## 6. **Examine posterior fit:**

```{r}
#| echo: false
#| fig-align: "center"
#| fig-width: 12
#| fig-height: 4
#| layout-ncol: 1
pars <- rstan::extract(fit_workflow, pars = c("alpha", "beta", "sigma"))
dat.fig <- data.frame(alpha = pars$alpha, beta = pars$beta, sigma = pars$sigma)
dat.fig <- reshape2::melt(dat.fig)
dat.fig |> ggplot(aes(x = value)) + 
  geom_histogram() + 
  facet_grid(.~ variable, scales = "free_x", labeller = label_parsed) + 
  labs(x = "Parameter", y = "Count", subtitle = "Posterior histrograms for model parameters")
```

## 6. **Examine posterior fit:**

```{r}
#| echo: false
#| fig-align: "center"
#| fig-width: 6
#| fig-height: 4
#| layout-ncol: 1
alpha <- pars$alpha
beta <- pars$beta
x <- seq(min(dat$height), max(dat$height), length.out = 501)
out <- matrix(nrow = length(x), ncol = length(alpha))
for (i in 1:length(alpha)) out[, i] <- alpha[i] + beta[i] * x
mean <- apply(out, 1, mean)
lower <- apply(out, 1, function(x) quantile(x, probs = 0.025))
upper <- apply(out, 1, function(x) quantile(x, probs = 0.975))
dat.fig <- data.frame(x, mean, lower, upper)
dat.fig |> ggplot(aes(x = x, y = mean)) + 
  geom_line() + 
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.3) + 
  geom_point(data = dat, aes(x = height, y = weight)) + 
  labs(x = "Height (inches)", y = "Weight (pounds)", subtitle = "Posterior regression line with 95% credible interval")
```

Regression line corresponds to posterior mean and 95% credible interval for $\mu = \alpha + \mathbf{x}_i \boldsymbol{\beta}$.

## 6. **Examine posterior fit:**

```{r}
#| echo: false
#| fig-align: "center"
#| fig-width: 6
#| fig-height: 4
#| layout-ncol: 1
alpha <- pars$alpha
beta <- pars$beta
x <- seq(min(dat$height), max(dat$height), length.out = 501)
out <- matrix(nrow = length(x), ncol = length(alpha))
for (i in 1:length(alpha)) out[, i] <- alpha[i] + beta[i] * x
mean <- apply(out, 1, mean)
lower <- apply(out, 1, function(x) quantile(x, probs = 0.025))
upper <- apply(out, 1, function(x) quantile(x, probs = 0.975))
dat.fig <- data.frame(x, mean, lower, upper)
dat.fig |> ggplot(aes(x = x, y = mean)) + 
  geom_line() + 
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.3) + 
  geom_point(data = dat, aes(x = height, y = weight)) + 
  labs(x = "Height (inches)", y = "Weight (pounds)", subtitle = "Posterior regression line with 95% credible interval")
```

```{stan output.var = "examine", eval = FALSE}
vector[n] mu;
for (i in 1:n) mu[i] = alpha + X[i, ] * beta;
```

## 7.**Check predictions:**

```{r}
#| echo: true
#| fig-align: "center"
#| fig-height: 4
#| layout-nrow: 1
Y_pred <- rstan::extract(fit_workflow, pars = "Y_pred")$Y_pred
ppc_dens_overlay(Y, Y_pred[1:100, ])
```

## 7. **Check predictions:** {.midi}

```{r}
#| echo: true
#| fig-align: "center"
#| fig-height: 1.75
#| fig-width: 4
#| layout-nrow: 2
#| layout-ncol: 2
ppc_stat(Y, Y_pred, stat = "mean") # from bayesplot
ppc_stat(Y, Y_pred, stat = "sd")
q025 <- function(y) quantile(y, 0.025)
q975 <- function(y) quantile(y, 0.975)
ppc_stat(Y, Y_pred, stat = "q025")
ppc_stat(Y, Y_pred, stat = "q975")
```

## 7. **Check predictions:** {.midi}

```{r}
#| echo: false
#| fig-align: "center"
#| fig-width: 6
#| fig-height: 4
#| layout-ncol: 1
Y_new <- rstan::extract(fit_workflow, pars = "Y_new")$Y_new
mean <- apply(Y_new, 2, mean)
lower <- apply(Y_new, 2, function(x) quantile(x, probs = 0.025))
upper <- apply(Y_new, 2, function(x) quantile(x, probs = 0.975))
dat.fig <- data.frame(x = X_new[, 1], mean, lower, upper)
dat.fig |> ggplot(aes(x = x, y = mean)) + 
  geom_line() + 
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.3) + 
  geom_point(data = dat, mapping = aes(x = height, y = weight)) + 
  labs(x = "Height (inches)", y = "Weight (pounds)", subtitle = "Posterior regression line with 95% predictive interval")
```

Regression line corresponds to posterior predictive distribution mean and 95% credible interval, $f(Y_{i'} | Y_1,\ldots,Y_n)$.

## `shinystan`

```{r, eval = FALSE}
library(shinystan)
Y <- dat$weight # need to define outcome as a global variable to be accessible
sso <- shinystan::launch_shinystan(fit_workflow)
```

## 8. Compare models

-   Suppose we would like to compare our original model with models that also includes sex and an interaction between sex and height.

\begin{align*}
\mathbb{E}[weight_i] &= \alpha + \beta_1 height_i\\
\mathbb{E}[weight_i] &= \alpha + \beta_1 height_i + \beta_2 sex_i\\
\mathbb{E}[weight_i] &= \alpha + \beta_1 height_i + \beta_2 sex_i + \beta_3 height_i sex_i
\end{align*}

## 8. Compare models {.midi}

```{r, echo = FALSE, eval = FALSE}
compiled_model <- stan_model(file = "/Users/sib2/Box Sync/Faculty/Education/biostat725-sp25/course-material/r-objects/linear_regression_workflow.stan")
X <- matrix(dat$height)
data_model1 <- list(
  n = nrow(dat), 
  p = ncol(X),
  Y = Y,
  X = X,
  n_new = n_new,
  X_new = X_new
)
fit_model1 <- sampling(compiled_model, data = data_model1)
saveRDS(fit_model1, file = "/Users/sib2/Box Sync/Faculty/Education/biostat725-sp25/course-material/r-objects/fit_workflow_model1.RDS")
X_model2 <- cbind(dat$height, dat$sex)
data_model2 <- list(
  n = nrow(dat), 
  p = ncol(X_model2),
  Y = Y,
  X = X_model2,
  n_new = nrow(X_model2),
  X_new = X_model2
)
fit_model2 <- sampling(compiled_model, data = data_model2)
saveRDS(fit_model2, file = "/Users/sib2/Box Sync/Faculty/Education/biostat725-sp25/course-material/r-objects/fit_workflow_model2.RDS")
X_model3 <- cbind(dat$height, dat$sex, dat$height * dat$sex)
data_model3 <- list(
  n = nrow(dat), 
  p = ncol(X_model3),
  Y = Y,
  X = X_model3,
  n_new = nrow(X_model3),
  X_new = X_model3
)
fit_model3 <- sampling(compiled_model, data = data_model3)
saveRDS(fit_model3, file = "/Users/sib2/Box Sync/Faculty/Education/biostat725-sp25/course-material/r-objects/fit_workflow_model3.RDS")
```

```{r, echo=FALSE}
fit_model1 <- readRDS(file = "/Users/sib2/Box Sync/Faculty/Education/biostat725-sp25/course-material/r-objects/fit_workflow_model1.RDS")
fit_model2 <- readRDS(file = "/Users/sib2/Box Sync/Faculty/Education/biostat725-sp25/course-material/r-objects/fit_workflow_model2.RDS")
fit_model3 <- readRDS(file = "/Users/sib2/Box Sync/Faculty/Education/biostat725-sp25/course-material/r-objects/fit_workflow_model3.RDS")
```

```{r}
###Compute individual WAIC
library(loo)
log_lik_model1 <- loo::extract_log_lik(fit_model1, parameter_name = "log_lik", merge_chains = TRUE)
log_lik_model2 <- loo::extract_log_lik(fit_model2, parameter_name = "log_lik", merge_chains = TRUE)
log_lik_model3 <- loo::extract_log_lik(fit_model3, parameter_name = "log_lik", merge_chains = TRUE)
waic_model1 <- loo::waic(log_lik_model1)
waic_model2 <- loo::waic(log_lik_model2)
waic_model3 <- loo::waic(log_lik_model3)

###Make a comparison
comp_waic <- loo::loo_compare(list("height_only" = waic_model1, "height_sex" = waic_model2, "interaction" = waic_model3))
print(comp_waic, digits = 2, simplify = FALSE)
```

## 8. Compare models {.midi}

```{r}
###Compute individual LOO-CV/LOO-IC
loo_model1 <- loo::loo(log_lik_model1)
loo_model2 <- loo::loo(log_lik_model2)
loo_model3 <- loo::loo(log_lik_model3)

###Make a comparison
comp_loo <- loo::loo_compare(list("height_only" = loo_model1, "height_sex" = loo_model2, "interaction" = loo_model3))
print(comp_loo, digits = 2, simplify = FALSE)
```

## The plan moving forward

-   We have now learned all of the skills needed to implement a Bayesian workflow.

-   The remainder of the course will be focused on introducing new models for types of data that are common when working in the biomedical data setting.

## Prepare for next class

-   Work on [HW 02](https://biostat725-sp26.netlify.app/hw/hw-02)

-   Complete reading to prepare for next Thursday's lecture

-   Thursday's lecture: Nonlinear Regression
